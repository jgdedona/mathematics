{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Mathematics\n",
    "# Statistical Inference\n",
    "# In-Class Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate a p-value for our data set.  First, let's import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import our data set.  You need to specify the absolute path of the data set (Dataset_Session5.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Similarity Metric (0.00-1.00)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18-Feb-18</td>\n",
       "      <td>0.0614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19-Feb-18</td>\n",
       "      <td>0.0913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20-Feb-18</td>\n",
       "      <td>0.0368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21-Feb-18</td>\n",
       "      <td>0.0213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-Feb-18</td>\n",
       "      <td>0.0098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Similarity Metric (0.00-1.00)\n",
       "0  18-Feb-18                         0.0614\n",
       "1  19-Feb-18                         0.0913\n",
       "2  20-Feb-18                         0.0368\n",
       "3  21-Feb-18                         0.0213\n",
       "4  22-Feb-18                         0.0098"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = r'Dataset_Session5.csv' #Specify absolute path here.\n",
    "data = pd.read_csv(dataset)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the data we want in the correct format: a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_series = np.array(list(data['Similarity Metric (0.00-1.00)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate some descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean and standard deviation\n",
    "m = np.average(data_series)\n",
    "sd = np.std(data_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the values in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mean: 0.07577999999999999 \n",
      " Standard Deviation: 0.14518890774895077\n"
     ]
    }
   ],
   "source": [
    "print(\" Mean: {}\".format(m), \"\\n\", \"Standard Deviation: {}\". format(sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, does it look like our value on 18 March 2018 is much different from the mean?\n",
    "\n",
    "We know that on 18 March 2018, our value is 0.8965.  We are performing a one-sample t-test in this case to see if our value at that date is anomalous.  We will take that sample to be the \"population mean,\" in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mean1 = 0.8965"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's calculate our t statistic and our two-tailed p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_1samp(data_series, pop_mean1, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic: -43.41977659265283\n",
      "p-value: 1.749492641970814e-46\n"
     ]
    }
   ],
   "source": [
    "print('t statistic: {}'.format(t))\n",
    "print('p-value: {}'.format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we reject the null hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now save your output.  Go to File -> Print Preview and save your final output as a PDF.  Turn in to your Instructor, along with any additional sheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Null Hypothesis = The mean tweet similarity metric for all days will be less than or equal to the tweet similarity metric from significant Russian political events among the target Twitter group.\n",
    "\n",
    "To reject the null hypothesis would mean that the results of our analysis indicate that there was as significant difference between the tweet similarity metric on 18 March 2018 and the mean tweet similarity metric of all days. Statistical inference is the process of utilizing sample data to draw conclusions regarding population parameters. The rejection of the null hypothesis in terms of statistical inference indicates that significant events, such as Russion political elections, significantly increase the similarity metric of tweets for this specific target population.\n",
    "\n",
    "It is important to note that this single \"test\" is of limited use on its own due to the countless confounding variables that have the potential to influence the results resulting from the methodology used. It would be necessary to draw several more samples centered around many different Russian events and focusing on several different target Twitter groups in order to generate inferences that measure high in terms of validity and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) We are able to detect an anomalous event given the dataset and alpha value of 5%. After performing a single sample t-test, the p-value was calculate to be 1.749e-46 (see both above and below). This value is MUCH lower than the alpha value of 0.05, indicating that the likelihood of our results occuring simply due to chance is very, very low. As a results of this, we can conclude to reject the null hypothesis, and we can infer that the presence of the Russian election did correlate with a significant increase in the tweet similarity metric.\n",
    "\n",
    "Additionally, the same conclusion can be come to based on the t-value, which was calculated at -43.42. Looking at the t-distribution table for single tailed t-tests at an alpha value of 0.05 and df = 59, you receive a critical t-value of 1.6716. This means that if the calculated t-value is higher than 1.6716 or lower than -1.6716, the null hypothesis can be rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) As stated in part b, the null hypothesis would be rejected based on the calculated p value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Assuming an alpha value of .01, the critical t-value increases to 2.3917. This occurs because by decreasing the alpha value, the cut-off for determining significance of the results becomes more stringent. This in turn means that the results based on the dependent variable must be further away from the mean in order to be determined significant. The distance from the mean in terms of standard deviation/sqrt(n) is represented by the t-value, so it makes sense that the cut-off value for determining significance would increase if the alpha value is decreased.\n",
    "\n",
    "Because the calculated t-value and p-value are so significant in this example, the conclusion would not be impacted by reducing the alpha value to .01. This is further evidence for the significance of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07577999999999999"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bar1 = sum(data_series)/len(data_series)\n",
    "x_bar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for dat in data_series:\n",
    "    total += (dat - x_bar1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1464141523214201"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd1 = (total/(len(data_series) - 1))**.5\n",
    "sd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = len(data_series)\n",
    "n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test(x_bar, pop_mean, sd, n):\n",
    "    t = (x_bar - pop_mean)/(sd/(n**.5))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-43.41977659265283"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test(x_bar1, pop_mean1, sd1, n1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
